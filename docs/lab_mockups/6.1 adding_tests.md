---
layout: tbd
title:  IBM Streams Lab - Adding a test for unexpected data
description:
weight: 30
---

# Adding a test for unexpected data
It is generally good practice to validate the data you receive from a feed. Data formats may not be well defined, ill-formed data does occur, and transmission noise can creep in as well. You do not want your application to fail when the data does not conform to its expectations. In this part, you will be receiving live data; who knows what it will do to your analytical process?

As an example of this kind of validation, you will add an operator that checks one attribute, the vehicle ID (id). In the data file all.cars, all records have an id value of the form “Cnnn” (presumably, with “C” for “car”). Even though it doesn’t at the moment, assume that your application depends on this format; for example, it could take a different action depending on the type of vehicle indicated by that first letter (say, “B” for “bus”); and there may be a system requirement that all vehicle IDs be exactly four characters long. Rather than silently dropping the tuple, however, it is better practice to save the “bad” data so you can audit what happened and later perhaps enhance the application.

In summary, the vehicle ID (id attribute) specifications are as follows:

| Criterion	| Value |
|-----------|-------|
| First character	| “C” |
| Length | 4 |

In other words, if any data comes in with an unexpected value for id, your program will shunt it aside as invalid data. There are several operators that can take care of this; which one you use is to some degree a matter of taste. You have already used one that fits the bill, the Filter. So let’s use a different one here.

The Split operator is designed to send tuples to different output ports (or none) depending on the evaluation of an arbitrary expression; this expression can, but does not have to, involve attribute values from the incoming tuple. It can have as many output ports as you need. In this case you only need two: one for the regular flow that you’ve been dealing with (the “valid” values), and one for the rest (the “not valid” ones).

The Split mechanism works as follows (see the example in Figure 5, below):

* The N output ports are numbered 0, 1, …, N-1.

* A parameter called index contains an arbitrary expression that returns a 64-bit integer
(an int64 or a, if unsigned, a uint64).

* This expression is evaluated for each incoming tuple.

* The expression’s value, n, determines which output port p the tuple is submitted to:

  * If n ≥ 0, p = n modulo N

  * If n < 0, the tuple is dropped

Figure 6. A Split operator with three output ports.

Remember
At any time during the steps below, use   Layout and   Fit to Content to keep the graph organized and visible.

1. Add a Split operator to the graph. In this case, you need one with two output ports.

  * In the graphical editor, find the Split operator, either by using the Find box or browsing down to Toolkits > spl > spl.utility > Split.

  * Drag a Split operator (not a template) into the canvas and drop it directly onto the  Throttled stream (output of the Throttled operator).

  * Drag an Output Port from the palette (under Design) onto the Split operator. This gives it a second output port.

1. Capture the Split’s second output stream in a file.

  * Add a FileSink to the graph.

  * Drag a stream from the second output of the Split to the input of the new FileSink.

  * Drag the LocationType schema from the palette (under Current Graph/Schemas) onto the new stream. This turns it from dashed to solid.

  Notice that the new stream from the Split’s first output port is already solid: it automatically inherits the schema from the original Throttled stream.

1. Edit the properties of each of the new streams; in the General tab, rename the first stream (the one that goes to Filtered) to Expected; rename the second to Unexpected.

1. Configure the Split operator. Because it has two output streams, it is better to set a descriptive alias than to blank it out; otherwise, it would be known by the name of the first output stream (Expected), which is somewhat misleading.

  * Edit the operator properties. In the General tab, Rename it to IDChecker.

  * In the Param tab, click Add…; check index and click OK.

  * In the Value field for the index parameter, type the following exactly (NOTE: the "l" after 0 and 1 is a lowercase letter ell, to indicate a “long”, 64-bit integer):

        substring(id,0,1) == "C" && length(id) == 4 ? 0l : 1l

    How to read this? “If the substring of the id attribute starting at offset zero with length one (in other words, the first character of id) is ‘C’ and the length of the id attribute is four, then zero; otherwise one.” So, proper IDs go out from the first port (Expected), and everything else goes out from the second port, Unexpected.

    SPL expression language syntax
    The syntax <boolean-expression> ? <action-if-true> : <action-if-false>
    is known from C, Java, and other languages. The functions substring(string,start,length) and length(string) are from the Standard Toolkit. The suffix “l” (the letter ell) indicates that the numbers are 64-bit values (“long” integers). SPL does not make implicit type conversions; integer numbers with no suffix are 32-bit values, and assigning one to a 64-bit parameter would raise an error.

1. Configure the new FileSink operator. You’ve used a FileSink in two previous parts, so refer back to those if you forgot how to do it.

  * First Rename it to ErrWriter.

  * Set the following parameter values:

| Parameter | Value |
|-----------|-------|
| file | "error.observations" |
| flush | 2u |
| format | csv |
| quoteStrings | false |


Flushing buffered file writes
FileSink performs buffered file I/O, meaning that it writes to buffers maintained by system libraries rather than directly to disk. These buffers are only written out to disk (flushed) as they fill up, or when the requesting application terminates. When the output is a slow trickle, this can mean that you will not see anything in the file for a long time. Setting flush to 2u (the u is for “unsigned” integer) guarantees that you will see data at least in batches of two records.

1. Save, launch the app, and verify that the original output files, filtered.cars and average.speeds, are being written to the data directory as before, and that the new output file (error.observations) has at least two records in it, after a suitable amount of time: the input file contains two records with a malformed ID (and other abnormal attribute values as well).
