{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Prerequisites\n\nEnsure you are using a Python 3.5 kernel to run this notebook.\n\n## Setting up the streamsx.health Module\n\nFor this course, you'll need the streamsx.health module. Run the cell below to install it:"}, {"cell_type": "code", "metadata": {"collapsed": false}, "outputs": [], "source": "!pip install --upgrade \"git+https://github.com/IBMStreams/streamsx.health#egg=streamsx_health.ingest&subdirectory=ingest/common/python/package\"", "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## Setting up Bluemix\n\nOpen the Bluemix web portal and <a href=\"https://console.ng.bluemix.net/\" target=\"_blank\" rel=\"noopener noreferrer\">log in or sign up for a free Bluemix account</a>.\n\nEnsure that your Streaming Analytics service is running in Bluemix.\n\nIf you don\u2019t have a service, you can create one as follows:  \n1. Click **Catalog** or **Create Service**, browse for `Streaming Analytics` and then click on it. <br>\n1. Follow the instructions on the Streaming Analytics catalog page, type the *Service name* to set up your service.<br>\n<img src='https://github.com/orzade/streamsx-notebooks/blob/master/servicename.png?raw=true' alt=\"Type your service name and click on Create\" title=\"Streaming Analytics catalog - Type your service name\"></img><br>\n1. Click **Create** to open the Streaming Analytics service dashboard. Your service starts automatically.\n\n<a id=\"setupservice\"></a>\n## Set up access to the service\n\nYou must provide the information that your streaming app needs to access the service.\nRun the cell below to provide your service name and credentials. If you are not prompted to enter the service credentials, click **Kernel -> Restart** on the menu bar and rerun the cells.\n"}, {"cell_type": "code", "metadata": {"collapsed": false}, "outputs": [{"text": "Streaming Analytics service name:Streaming Analytics-63\n", "name": "stdout", "output_type": "stream"}], "source": "service_name = input(\"Streaming Analytics service name:\")", "execution_count": 1}, {"cell_type": "code", "metadata": {"collapsed": false}, "outputs": [{"text": "Streaming Analytics credentials:\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n", "name": "stdout", "output_type": "stream"}], "source": "import getpass\ncredentials=getpass.getpass('Streaming Analytics credentials:')", "execution_count": 2}, {"cell_type": "markdown", "metadata": {}, "source": "**Tip:** \nTo copy your service credentials, open the Streaming Analytics service dashboard click **Service Credentials**, then **View Credentials**, and finally click the Copy icon and paste your service credentials when prompted.<br>\n<img src='https://github.com/orzade/streamsx-notebooks/blob/master/copyservicecredentials.png?raw=true' alt=\"Copy your service credentials\" title=\"Streaming Analytics catalog - Copy your service credentials\"></img>\n<br>\n"}, {"cell_type": "markdown", "metadata": {"nbpresent": {"id": "908f9bdf-26e3-4fee-8480-c0c75d4d0042"}}, "source": "# Lab 1 - Create a simple Python application\n\n## Step 1 - Develop a basic Python application\n\nIn this exercise, we will develop a simple streaming application to process sample data.\n\n### Instructions\n\n1. Import the necessary modules from the streamsx package. We will need:\n    - the schema import, from streamsx.topology\n    - the Topology import, from streamsx.topology\n    - the entire streamsx.topology.context module <br><br>\n2. Create a function, called 'Observations'\n    - Name a variable jsonStr and assign it the sample patient data shown in the section below\n    - Import the json module, and load the JSON data into a dictionary called 'dictObj'\n    - Import the time module and slow your source by one second\n    - Yield dictObj with each iteration through the above code\n    - Finally, to simulate a continuous source, the data should be generated infinitely. <br><br>\n3.  Create a new topology. Then, create a new stream 'patientData' from the data source we defined above.\n4. Print the data stream in the console.\n5. Submit the application over Bluemix.\n\n### Sample Data\n\n{\"patientId\":\"patient-1\", \"device\":{\"id\":\"VitalsGenerator\", \"locationId\":\"bed1\"}, \"readingSource\": {\"id\":123, \"deviceId\":\"VitalsGenerator\", \"sourceType\":\"generated\"}, \"reading\": {\"ts\": 605, \"uom\":\"bpm\", \"value\":82.56785326532197, \"readingType\": {\"code\":\"8867-4\", \"system\":\"streamsx.heath/1.0\"}}}"}, {"cell_type": "code", "metadata": {"scrolled": true, "collapsed": false, "nbpresent": {"id": "315dedf8-4caa-49bf-9c7a-4a0a86cb0b29"}}, "outputs": [], "source": "#Imports\nfrom streamsx.topology import schema\nfrom streamsx.topology.topology import Topology\nfrom streamsx.topology.context import *\nimport json\nimport time\n\n#Set up access to Streaming Analytics service\nvs={'streaming-analytics': [{'name': service_name, 'credentials': json.loads (credentials)}]}\ncfg = {}\ncfg[ConfigParams.VCAP_SERVICES] = vs\ncfg[ConfigParams.SERVICE_NAME] = service_name\n\n# define data source\ndef Observations():\n    while True:  \n        jsonStr =  '''{\"patientId\":\"patient-1\", \"device\":{\"id\":\"VitalsGenerator\",\n                    \"locationId\":\"bed1\"}, \"readingSource\": {\"id\":123, \"deviceId\":\n                    \"VitalsGenerator\", \"sourceType\":\"generated\"},\n                    \"reading\": {\"ts\": 605, \"uom\":\"bpm\", \"value\":82.56785326532197,\n                    \"readingType\": {\"code\":\"8867-4\", \"system\":\"streamsx.heath/1.0\"}}}''' \n        \n        dictObj = json.loads(jsonStr)\n        time.sleep(1)\n        yield dictObj\n        \n# Create Topology and read from data source\ntopo = Topology(\"patient_data\")\npatientData = topo.source(Observations)    \n\n# Print\npatientData.print()\n\n# Submit on Bluemix\nsubmit('STREAMING_ANALYTICS_SERVICE', topo, cfg)", "execution_count": null}, {"cell_type": "markdown", "metadata": {"nbpresent": {"id": "4eea0842-9947-46d3-b671-9ae238a11786"}, "collapsed": true}, "source": "# Lab 2 - Handle a diversity of patient data\n\n## Step 1 - Filter data using lambda function\n\nIn this exercise, we will modify the application to only handle heart rate from the patient readings.\n\n1.  Filter out all the readings whose 'code' value is not '8867-4'. Assign the name 'heartRate' to the filtered stream. \n2.  Fix the sink() function to sink the heartRate stream instead.\n3.  Submit the application over Bluemix and view the output on your Streams Console.\n\n## Step 2 - Submit the patient simulator job\n\n1. On the Streams Console, click the 'Submit Job' button\n2.  Leave the instance field as its default value\n3.  Select 'Specify the URL of the application bundle' and enter the following URL:\n    https://github.com/IBMStreams/streamsx.health/releases/download/v0.1/com.ibm.streamsx.health.simulate.beacon.services.HealthDataBeaconService.sab\n4. Click 'Submit.'<br>\n    \n## Step 3 - Subscribe to the simulator\n2.  Replace our Observations source with a Subscribe call to the patient simulator. The topic to subscribe to is 'ingest-beacon'.\n3.  Make sure the simulator is running before you submit any subsequent applications.\n4.  Submit your application over Bluemix and view the output."}, {"cell_type": "code", "metadata": {"nbpresent": {"id": "cf4e0dd9-3f44-41e6-a3ea-93edb515fc3c"}, "collapsed": false}, "outputs": [], "source": "from streamsx.topology import schema\nfrom streamsx.topology.topology import Topology\nfrom streamsx.topology.context import *\nimport json\nimport time\n\n#Set up access to Streaming Analytics service\nvs={'streaming-analytics': [{'name': service_name, 'credentials': json.loads (credentials)}]}\ncfg = {}\ncfg[ConfigParams.VCAP_SERVICES] = vs\ncfg[ConfigParams.SERVICE_NAME] = service_name\n\n# Define data source\ndef Observations():\n    while True:\n        jsonStr =  '{\"patientId\":\"patient-1\", \"device\":{\"id\":\"VitalsGenerator\", \"locationId\":\"bed1\"}, \"readingSource\": {\"id\":123, \"deviceId\":\"VitalsGenerator\", \"sourceType\":\"generated\"}, \"reading\": {\"ts\": 605, \"uom\":\"bpm\", \"value\":82.56785326532197, \"readingType\": {\"code\":\"8867-4\", \"system\":\"streamsx.heath/1.0\"}}}'\n        dictObj = json.loads(jsonStr)\n        time.sleep(1)\n        yield dictObj\n        \n# Create Topology and read from data source\ntopo = Topology(\"patient_data\")\npatientData = topo.subscribe('ingest-beacon', schema.CommonSchema.Json)\n\n# Create new data stream called heartRate\nheartRate = patientData.filter(lambda tuple: (tuple['reading']['readingType']['code']==\"8867-4\"))\n\n# Only print heart rate\nheartRate.print()\n\n\n# Submit on Bluemix\nsubmit('STREAMING_ANALYTICS_SERVICE', topo, cfg)", "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "# Lab 3 - Anonymize and average data \n\n## Step 1 - Anonymize Patient Data\n\nIn this exercise, we are going to 'anonymize' patient data by hashing identifying information.\n\n1. Import the hashlib module\n2. Make a function that...\n    * Has a single parameter\n    * Hashes 'patientId' and 'locationId' using the sha256() algorithm\n    * Returns the modified tuple \n3.  Modify the content of each tuple on the patientData stream by calling the anonymize method. Name the new stream 'patientX.' This step should precede the filter.\n4.  Submit over Bluemix and view the output.\n\n## Step 2 - Keeping States\n\nIn this exercise, we will keep state of the last 10 tuples from the patient data stream. For each new tuple that comes in, we will calculate the moving average from the last 10 tuples.\n\n1. Import the getReadingValue function from the streamsx_health.ingest.Observation module.\n2. Create a new callable class.  The class should have a field called last_n, which is a list that keeps track of the last n tuples.\n    *  The call method of the class should take a single parameter, n, which is the number of tuples over which to calculate the average\n    * When the call method is called, append the tuple's heart rate reading to the list.  If the length of the list > n, pop the oldest tuple.\n    * Return the average of all values from the list \n2.  Calculate the moving average of heart rate, over the last 10 tuples, calling the new stream 'avgHr'\n3. Submit the application over Bluemix, and view the results - a simple list of average heart rate readings.\n"}, {"cell_type": "code", "metadata": {"collapsed": false}, "outputs": [], "source": "from streamsx.topology import schema\nfrom streamsx.topology.topology import Topology\nimport streamsx.topology.context\nimport json\nimport time\nimport hashlib\n\n# Import Observation\nfrom streamsx_health.ingest.Observation import getReadingValue\n\n# Set up access to Streaming Analytics service\nvs={'streaming-analytics': [{'name': service_name, 'credentials': json.loads (credentials)}]}\ncfg = {}\ncfg[ConfigParams.VCAP_SERVICES] = vs\ncfg[ConfigParams.SERVICE_NAME] = service_name\n\n# Anonymize patient data        \ndef anonymize(tuple):\n    tuple['patientId'] = hashlib.sha256(tuple['patientId'].encode('utf-8')).digest()\n    device = tuple['device']\n    device['locationId'] = hashlib.sha256(device['locationId'].encode('utf-8')).digest()\n    return tuple\n\n# Define Callable Class to keep state of last 10 tuples\nclass Avg:\n    def __init__(self, n):\n        self.n = n\n        self.last_n = []\n        \n    def __call__(self, tuple):\n        self.last_n.append(getReadingValue(tuple))\n        if (len(self.last_n) > self.n):\n            self.last_n.pop(0)   \n        return sum(self.last_n)/len(self.last_n)\n        \n# Create Topology and read from data source\ntopo = Topology(\"patient_data\")\npatientData = topo.subscribe('ingest-beacon', schema.CommonSchema.Json)\n\n# Anonymize patient data before processing\npatientX = patientData.map(anonymize)\n\n# Create new data stream called heartRate\nheartRate = patientX.filter(lambda tuple: (tuple['reading']['readingType']['code']==\"8867-4\"))\n\n# Avg Heart Rate stream\navgHr = heartRate.map(Avg(10))\n\n# Print Avg Heart Rate\navgHr.print()\n\n# Submit on Bluemix\nsubmit('STREAMING_ANALYTICS_SERVICE', topo, cfg)", "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "# Lab 4 - Visualize data in Python notebook\n\n## Step 1 - Viewing Data\n\n1. Create view from Average Heart Rate Stream:  avgHrView(name='AverageHR')\n3.  Launch application and proceed to the cells below.\n  "}, {"cell_type": "code", "metadata": {"collapsed": false}, "outputs": [], "source": "from streamsx.topology import schema\nfrom streamsx.topology.topology import Topology\nfrom streamsx.topology.context import *\nimport json\nimport time\nimport hashlib\n\n# Import Observation\nfrom streamsx_health.ingest.Observation import getReadingValue\n\n# Set up access to Streaming Analytics service\nvs={'streaming-analytics': [{'name': service_name, 'credentials': json.loads (credentials)}]}\ncfg = {}\ncfg[ConfigParams.VCAP_SERVICES] = vs\ncfg[ConfigParams.SERVICE_NAME] = service_name\n\n\n# Anonymize patient data        \ndef anonymize(tuple):\n    tuple['patientId'] = hashlib.sha256(tuple['patientId'].encode('utf-8')).digest()\n    device = tuple['device']\n    device['locationId'] = hashlib.sha256(device['locationId'].encode('utf-8')).digest()\n    return tuple\n\n# define Callable Class to keep state of last 10 tuples\nclass Avg:\n    def __init__(self, n):\n        self.n = n\n        self.last_n = []\n    def __call__(self, tuple):\n        self.last_n.append(getReadingValue(tuple))\n        if (len(self.last_n) > self.n):\n            self.last_n.pop(0)\n        return sum(self.last_n)/len(self.last_n)\n        \n# Create Topology and read from data source\ntopo = Topology(\"patient_data\")\npatientData = topo.subscribe('ingest-beacon', schema.CommonSchema.Json)\n\n# Anonymize patient data before processing\npatientX = patientData.map(anonymize)\n\n# Create new data stream called heartRate\nheartRate = patientX.filter(lambda tuple: (tuple['reading']['readingType']['code']==\"8867-4\"))\n\n# Avg Heart Rate stream\navgHr = heartRate.map(Avg(10))\n\n# Create a view for Average HR\navgHrView = avgHr.view()\n\n# Print Avg Heart Rate\navgHr.print()\n\n# Submit on Bluemix\nsubmit('STREAMING_ANALYTICS_SERVICE', topo, cfg)", "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## Step 2a - Fetch View Data\n\nThe following code shows how to fetch view data from a view that we have set up in a Streams application.\n\n1.  Import deque from the collections module. \n2. Create a deque called `plotQueue` that holds up to 2000 tuples.\n3. Call avgHrView.start_data_fetch()\n4. Create a data_collecter function that iterates through your view and appends each value to plotQueue.\n5.  Run data_collector in a background thread and save data in plotQueue - plotQueue will be used to visualize data in the next cell."}, {"cell_type": "code", "metadata": {"collapsed": false}, "outputs": [], "source": "from collections import deque\n\n# Create a buffer of 2000 tuples for plotting\nplotQueue = deque([], 2000)    \nview = avgHrView.start_data_fetch() \n\ndef data_collector(view):\n    for d in iter(view.get, None):\n        plotQueue.append(float(d))\n\nfrom IPython.lib import backgroundjobs as bg\njobs = bg.BackgroundJobManager()\njobs.new(data_collector, view)", "execution_count": null}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": "## Step 2b - Visualize View Data using Matplotlib\n\nThe following cell shows how to view realtime data in Jupyter Notebook.\nThe code updates the view once every second.  \nWe plot data from the plotQueue variable.\n\nAs long as the data view and the view is running, you can start and stop the following cell when you work on your analytics and visualizations."}, {"cell_type": "code", "metadata": {"collapsed": false}, "outputs": [], "source": "# Visualize view data in a line graph\n%matplotlib inline\nimport time\nfrom IPython import display\nimport pylab as pl\n\npl.rcParams['figure.figsize'] = (14.0, 8.0)\n\nwhile (True):\n    pl.clf()\n    ax = pl.gca()\n    ax.set_autoscale_on(False)\n    ax.plot(plotQueue)\n    ax.axis([0, 2000, 50, 120])\n    display.display(pl.gcf())\n    print(len(plotQueue))\n    display.clear_output(wait=True)\n    time.sleep(1.0)\n", "execution_count": null}, {"cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "source": "", "execution_count": null}], "metadata": {"nbpresent": {"themes": {}, "slides": {"4576f8c7-5923-40b5-9428-f93816cdb3c3": {"id": "4576f8c7-5923-40b5-9428-f93816cdb3c3", "prev": "64cf6d43-0bcd-4852-9edf-f34ed27c0268", "regions": {"541f47da-9924-42fb-92e4-604912bd8650": {"content": {"part": "whole", "cell": "cf4e0dd9-3f44-41e6-a3ea-93edb515fc3c"}, "id": "541f47da-9924-42fb-92e4-604912bd8650", "attrs": {"height": 0.8, "width": 0.8, "y": 0.1, "x": 0.1}}}}, "a6d39083-6cbe-43a1-b708-37f62644a0bd": {"id": "a6d39083-6cbe-43a1-b708-37f62644a0bd", "prev": null, "regions": {"d77984e4-6f46-4a7a-b569-534f721164ab": {"content": {"part": "whole", "cell": "908f9bdf-26e3-4fee-8480-c0c75d4d0042"}, "id": "d77984e4-6f46-4a7a-b569-534f721164ab", "attrs": {"height": 0.8, "width": 0.8, "y": 0.1, "x": 0.1}}}}, "69f0a312-ecfc-4508-bc4b-0658265c9545": {"id": "69f0a312-ecfc-4508-bc4b-0658265c9545", "prev": "429e034a-fc51-4734-8597-8233f00b1ca0", "regions": {"c79a8c13-c882-4633-b33a-709a715ac359": {"content": {"part": "whole", "cell": "684e54af-8510-4236-8d44-e385759f11f2"}, "id": "c79a8c13-c882-4633-b33a-709a715ac359", "attrs": {"height": 0.8, "width": 0.8, "y": 0.1, "x": 0.1}}}}, "64cf6d43-0bcd-4852-9edf-f34ed27c0268": {"id": "64cf6d43-0bcd-4852-9edf-f34ed27c0268", "prev": "ec6e26ad-1a15-477c-9f16-095cccf3b622", "regions": {"b4495fcd-3e14-4aa2-a668-211ff89a5d55": {"content": {"part": "whole", "cell": "4eea0842-9947-46d3-b671-9ae238a11786"}, "id": "b4495fcd-3e14-4aa2-a668-211ff89a5d55", "attrs": {"height": 0.8, "width": 0.8, "y": 0.1, "x": 0.1}}}}, "429e034a-fc51-4734-8597-8233f00b1ca0": {"id": "429e034a-fc51-4734-8597-8233f00b1ca0", "prev": "4576f8c7-5923-40b5-9428-f93816cdb3c3", "regions": {"3e564196-15de-4439-b62e-c69a256999c4": {"content": {"part": "whole", "cell": "d14afdc1-1169-42f0-8888-f2a817d13996"}, "id": "3e564196-15de-4439-b62e-c69a256999c4", "attrs": {"height": 0.8, "width": 0.8, "y": 0.1, "x": 0.1}}}}, "b378bfd6-575a-4aa7-b276-f706500a4ef6": {"id": "b378bfd6-575a-4aa7-b276-f706500a4ef6", "prev": "a6d39083-6cbe-43a1-b708-37f62644a0bd", "regions": {"c28e1060-3b74-4c75-bac0-8587f87d66f0": {"content": {"part": "whole", "cell": "979be16b-e571-4324-856a-1c7124de7b18"}, "id": "c28e1060-3b74-4c75-bac0-8587f87d66f0", "attrs": {"height": 0.8, "width": 0.8, "y": 0.1, "x": 0.1}}}}, "9a4a3d93-b83d-4a71-b255-201e7b10570f": {"id": "9a4a3d93-b83d-4a71-b255-201e7b10570f", "prev": "69f0a312-ecfc-4508-bc4b-0658265c9545", "regions": {"1575c709-30c1-46af-ba43-56d7ca938a8b": {"content": {"part": "whole", "cell": "f104cf13-b382-4f4b-974e-465e0853713c"}, "id": "1575c709-30c1-46af-ba43-56d7ca938a8b", "attrs": {"height": 0.8, "width": 0.8, "y": 0.1, "x": 0.1}}}}, "ec6e26ad-1a15-477c-9f16-095cccf3b622": {"id": "ec6e26ad-1a15-477c-9f16-095cccf3b622", "prev": "b378bfd6-575a-4aa7-b276-f706500a4ef6", "regions": {"b441a92e-7724-4866-907c-6fd9a98c1266": {"content": {"part": "whole", "cell": "315dedf8-4caa-49bf-9c7a-4a0a86cb0b29"}, "id": "b441a92e-7724-4866-907c-6fd9a98c1266", "attrs": {"height": 0.8, "width": 0.8, "y": 0.1, "x": 0.1}}}}}}, "anaconda-cloud": {}, "kernelspec": {"display_name": "Python 3.5 (Experimental) with Spark 1.6", "name": "python3", "language": "python"}, "language_info": {"version": "3.5.2", "mimetype": "text/x-python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "name": "python"}}, "nbformat_minor": 0, "nbformat": 4}
